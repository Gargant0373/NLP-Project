{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6424e9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 87 XML files from all countries.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "data_path = Path(\"ParlaMint\")\n",
    "if not data_path.exists():\n",
    "    raise FileNotFoundError(\"Please run ./download_data.sh to download the data.\")\n",
    "\n",
    "# Load XML files from ALL countries\n",
    "xml_en_files = []\n",
    "for country_dir in (data_path / \"Samples\").iterdir():\n",
    "    if country_dir.is_dir():\n",
    "        country_code = country_dir.name.replace(\"ParlaMint-\", \"\")\n",
    "        xml_en_files.extend(list(country_dir.rglob(\"*-en_*.ana.xml\")))\n",
    "\n",
    "print(f\"Found {len(xml_en_files)} XML files from all countries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee29c9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 5432 sentences from 87 XML files.\n",
      "\n",
      "Clean Text for first sentence:\n",
      "Madam President, I would like\n",
      "\n",
      "Token metadata for first 3 tokens of first sentence:\n",
      "        text   type      lemma  pos                        msd  sem\n",
      "0      Madam   word      madam  NNP  UPosTag=PROPN|Number=Sing  Z1f\n",
      "1  President   word  President  NNP  UPosTag=PROPN|Number=Sing  Z1f\n",
      "2          ,  punct       None    Z              UPosTag=PUNCT   Z9\n",
      "\n",
      "First 5 rows of extracted data:\n",
      "                       u_id                      s_id  ...    entities       date\n",
      "0  i-BQ8dtftkuwhpor9i8CsgBV  i-7Gocwwgm1SAsUELPMWzXuE  ...          [] 2022-05-13\n",
      "1  i-BQ8dtftkuwhpor9i8CsgBV  i-7GodASKwaGTGUA8Kq8nQCL  ...  [PER, LOC] 2022-05-13\n",
      "2  i-BQ8dtftkuwhpor9i8CsgBV  i-7GodHw7T7ZphsKCgv74KaC  ...       [ORG] 2022-05-13\n",
      "3  i-BQ8dtftkuwhpor9i8CsgBV  i-7GodPmH4ygtVQDNXYCAFye  ...          [] 2022-05-13\n",
      "4  i-BQ8dtftkuwhpor9i8CsgBV  i-7GodVbSgqoxGw7YNAHGCP6  ...       [ORG] 2022-05-13\n",
      "\n",
      "[5 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "import pandas as pd \n",
    "\n",
    "NS = {\"tei\": \"http://www.tei-c.org/ns/1.0\"}\n",
    "\n",
    "def parse_parlamint_xml(xml_path):\n",
    "    tree = etree.parse(str(xml_path))\n",
    "    root = tree.getroot()\n",
    "\n",
    "    date_str = root.xpath(\".//tei:settingDesc/tei:setting/tei:date/@when\", namespaces=NS)\n",
    "    speech_date = pd.to_datetime(date_str[0]) if date_str else None\n",
    "\n",
    "    data = []\n",
    "    utterances = root.xpath(\"//tei:u\", namespaces=NS)\n",
    "\n",
    "    for u in utterances:\n",
    "        u_id = u.get(\"{http://www.w3.org/XML/1998/namespace}id\")\n",
    "        speaker = u.get(\"who\")\n",
    "        ana = u.get(\"ana\", \"\")\n",
    "        topics = [a.replace(\"topic:\", \"\") for a in ana.split() if \"topic:\" in a]\n",
    "\n",
    "        sentences = u.xpath(\".//tei:s\", namespaces=NS)\n",
    "        for s in sentences:\n",
    "            s_id = s.get(\"{http://www.w3.org/XML/1998/namespace}id\")\n",
    "            \n",
    "            sentiment_node = s.xpath(\".//tei:measure[@type='sentiment']\", namespaces=NS)\n",
    "            sentiment_score = float(sentiment_node[0].get(\"quantity\")) if sentiment_node else None\n",
    "            \n",
    "            named_entities = s.xpath(\".//tei:name/@type\", namespaces=NS)\n",
    "            \n",
    "            tokens = []\n",
    "            reconstructed_text = \"\"\n",
    "            \n",
    "            token_elements = s.xpath(\".//tei:w | .//tei:pc\", namespaces=NS)\n",
    "            \n",
    "            for i, token_el in enumerate(token_elements):\n",
    "                token_text = token_el.text or \"\"\n",
    "                \n",
    "                token_data = {\n",
    "                    \"text\": token_text,\n",
    "                    \"type\": \"word\" if token_el.tag.endswith(\"w\") else \"punct\",\n",
    "                    \"lemma\": token_el.get(\"lemma\"),\n",
    "                    \"pos\": token_el.get(\"pos\"),\n",
    "                    \"msd\": token_el.get(\"msd\"),\n",
    "                    \"sem\": token_el.get(\"function\")\n",
    "                }\n",
    "                tokens.append(token_data)\n",
    "                \n",
    "                reconstructed_text += token_text\n",
    "                if token_el.get(\"join\") != \"right\" and i < len(token_elements) - 1:\n",
    "                    reconstructed_text += \" \"\n",
    "\n",
    "            data.append({\n",
    "                \"u_id\": u_id,\n",
    "                \"s_id\": s_id,\n",
    "                \"speaker\": speaker,\n",
    "                \"topics\": topics,\n",
    "                \"sentiment\": sentiment_score,\n",
    "                \"entities\": list(set(named_entities)),\n",
    "                \"text\": reconstructed_text,\n",
    "                \"tokens\": tokens, \n",
    "                \"date\": speech_date,\n",
    "            })\n",
    "            \n",
    "    return data\n",
    "\n",
    "all_data = []\n",
    "for xml_file in xml_en_files:\n",
    "    all_data.extend(parse_parlamint_xml(xml_file))\n",
    "\n",
    "xml_df = pd.DataFrame(all_data)\n",
    "print(f\"Extracted {len(xml_df)} sentences from {len(xml_en_files)} XML files.\")\n",
    "\n",
    "if not xml_df.empty:\n",
    "    print(\"\\nClean Text for first sentence:\")\n",
    "    print(xml_df.iloc[0]['text'])\n",
    "    print(\"\\nToken metadata for first 3 tokens of first sentence:\")\n",
    "    print(pd.DataFrame(xml_df.iloc[0]['tokens']).head(3))\n",
    "\n",
    "columns_to_show = ['u_id', 's_id', 'speaker', 'topics', 'sentiment', 'entities', 'date']\n",
    "print(\"\\nFirst 5 rows of extracted data:\")\n",
    "print(xml_df[columns_to_show].head(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
